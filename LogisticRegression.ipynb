{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "import pandahouse as ph\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "HOST = ''\n",
    "DB = ''\n",
    "\n",
    "#чтение данных с кликхауса или файла\n",
    "def readClickHouse(query = '', fileName = '1.csv', host = HOST, db = DB):\n",
    "    if host != '':\n",
    "        data = ph.read_clickhouse(query, connection={'host': host, 'database': db})\n",
    "        open(fileName, 'w').write(data.to_csv())\n",
    "    else:\n",
    "        try:\n",
    "            f = open(fileName)\n",
    "        except IOError as e:\n",
    "            print('Не удалось открыть файл')\n",
    "        else:\n",
    "            data = pd.read_csv(fileName, sep = ',')\n",
    "            data = data[[x for x in data.columns if x != 'Unnamed: 0']]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTrainQuery(offer_id = 3, date = 'yesterday()'):\n",
    "    return '''\n",
    "    select \n",
    "    session_id,\n",
    "    min(datetime) as start_time,\n",
    "    max(datetime) as end_time,\n",
    "    max(datetime) - min(datetime) as duration,\n",
    "    count(*) as clicks_count,\n",
    "    max(depth) as max_depth,\n",
    "    countIf(order_id != '') as orders_count,\n",
    "    countIf(page_type = 'basket') as basket_count,\n",
    "    countIf(page_type = 'card') as card_count,\n",
    "    countIf(page_type = 'category') as category_count,\n",
    "    countIf(page_type = 'home') as home_count,\n",
    "    countIf(page_type = 'none') as none_count,\n",
    "    countIf(page_type = 'order') as order_count,\n",
    "    countIf(page_type = 'other') as other_count,\n",
    "    countIf(page_type = 'typ') as typ_count,\n",
    "    clicks_count - sum(is_internal) as outside_count,\n",
    "    sum(is_internal) as inside_count,\n",
    "    anyLast(source) as last_source,\n",
    "    uniq(source) as source_count\n",
    "    from {db}.rtb\n",
    "    where offer_id = ''' + str(offer_id) + ''' and date = ''' + date + '''\n",
    "    group by session_id\n",
    "'''\n",
    "\n",
    "def getTestQuery(offer_id = 3, date = 'today()'):\n",
    "    return '''\n",
    "    select  \n",
    "    session_id,\n",
    "    min(datetime) as start_time,\n",
    "    max(datetime) as end_time,\n",
    "    max(datetime) - min(datetime) as duration,\n",
    "    count(*) as clicks_count,\n",
    "    max(depth) as max_depth,\n",
    "    countIf(order_id != '') as orders_count,\n",
    "    countIf(page_type = 'basket') as basket_count,\n",
    "    countIf(page_type = 'card') as card_count,\n",
    "    countIf(page_type = 'category') as category_count,\n",
    "    countIf(page_type = 'home') as home_count,\n",
    "    countIf(page_type = 'none') as none_count,\n",
    "    countIf(page_type = 'order') as order_count,\n",
    "    countIf(page_type = 'other') as other_count,\n",
    "    countIf(page_type = 'typ') as typ_count,\n",
    "    clicks_count - sum(is_internal) as outside_count,\n",
    "    sum(is_internal) as inside_count,\n",
    "    anyLast(source) as last_source,\n",
    "    uniq(source) as source_count\n",
    "    from {db}.rtb\n",
    "    where offer_id = ''' + str(offer_id) + ''' and date = ''' + date + '''\n",
    "    group by session_id\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Загружаем данные из файлов\n",
    "train = readClickHouse(getTrainQuery(3, 'yesterday()'), 'train_.csv', '')\n",
    "test = readClickHouse(getTestQuery(3, 'today()'), 'test_.csv', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Удаляем неиспользуемые столбцы\n",
    "DROP_COL = ['start_time', 'end_time', 'last_source', 'session_id', 'typ_count']\n",
    "train.loc[train['typ_count'] > 0, 'typ_count'] = 1\n",
    "\n",
    "X_train = np.array(train.drop(DROP_COL, axis=1))\n",
    "y_train = np.array(train['typ_count'])\n",
    "X_test = np.array(test.drop(DROP_COL, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 104657 entries, 0 to 104656\n",
      "Data columns (total 19 columns):\n",
      "session_id        104657 non-null object\n",
      "start_time        104657 non-null object\n",
      "end_time          104657 non-null object\n",
      "duration          104657 non-null int64\n",
      "clicks_count      104657 non-null int64\n",
      "max_depth         104657 non-null int64\n",
      "orders_count      104657 non-null int64\n",
      "basket_count      104657 non-null int64\n",
      "card_count        104657 non-null int64\n",
      "category_count    104657 non-null int64\n",
      "home_count        104657 non-null int64\n",
      "none_count        104657 non-null int64\n",
      "order_count       104657 non-null int64\n",
      "other_count       104657 non-null int64\n",
      "typ_count         104657 non-null int64\n",
      "outside_count     104657 non-null int64\n",
      "inside_count      104657 non-null int64\n",
      "last_source       59728 non-null object\n",
      "source_count      104657 non-null int64\n",
      "dtypes: int64(15), object(4)\n",
      "memory usage: 15.2+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "def cross_val_predict_proba(estimator, X_train, y_train, X_test, random_state=None, n_splits=5):\n",
    "    y_test = np.zeros((len(X_test), n_splits), np.float32)\n",
    "    \n",
    "    kfold = KFold(n_splits=n_splits, \n",
    "                  shuffle=True,\n",
    "                  random_state=random_state)\n",
    "\n",
    "    y_predict = np.zeros_like(y_train, np.float32)\n",
    "    for i, (train_idx, test_idx) in enumerate(kfold.split(y_train)):\n",
    "        estimator.fit(X_train[train_idx], y_train[train_idx])\n",
    "        y_predict[test_idx] = estimator.predict_proba(X_train[test_idx])[:, 1]\n",
    "        y_test[:, i] = estimator.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    return y_predict, np.mean(y_test, axis=1)\n",
    "\n",
    "# TODO: подобрать гиперпараметры отдельных моделей\n",
    "\n",
    "# инициализирем модели с подобранными гиперпараметрами\n",
    "estimators = [RandomForestClassifier(random_state=54232), \n",
    "              ExtraTreesClassifier(random_state=23412),\n",
    "              AdaBoostClassifier(random_state=24212), \n",
    "              GradientBoostingClassifier(random_state=2732982)]\n",
    "\n",
    "# получаем предсказания вероятностей ансамблей на кросс-валидации для обучающей выборки\n",
    "predicted = [cross_val_predict_proba(est, X_train, y_train, X_test) for est in estimators]\n",
    "\n",
    "X_train_stack = np.stack([p[0] for p in predicted], axis=1)\n",
    "X_test_stack = np.stack([p[1] for p in predicted], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df123 = pd.DataFrame(X_test_stack)\n",
    "# open('x_test_stack.csv', 'w').write(df123.to_csv())\n",
    "# df123 = pd.DataFrame(X_train_stack)\n",
    "# open('x_train_stack.csv', 'w').write(df123.to_csv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "kfold = KFold(shuffle=True, n_splits=4, random_state=19746)\n",
    "params = {'class_weight': ['balanced', None],\n",
    "          'penalty': ['l1', 'l2'],\n",
    "          'C': [0.4, 0.5, 1., 2., 2.5, 3., 3.5, 4.]}\n",
    "\n",
    "grid = GridSearchCV(LogisticRegression(), params, scoring='neg_log_loss', cv=kfold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=4, random_state=19746, shuffle=True),\n",
       "       error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'class_weight': ['balanced', None], 'penalty': ['l1', 'l2'], 'C': [0.4, 0.5, 1.0, 2.0, 2.5, 3.0, 3.5, 4.0]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_log_loss', verbose=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train_stack, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michaelg/anaconda3/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/michaelg/anaconda3/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/michaelg/anaconda3/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/michaelg/anaconda3/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/michaelg/anaconda3/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/michaelg/anaconda3/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_class_weight</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>11.361621</td>\n",
       "      <td>0.016202</td>\n",
       "      <td>-0.028467</td>\n",
       "      <td>-0.028407</td>\n",
       "      <td>3.5</td>\n",
       "      <td>None</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'class_weight': None, 'penalty': 'l1', 'C': 3.5}</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.028033</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028089</td>\n",
       "      <td>-0.028499</td>\n",
       "      <td>-0.029276</td>\n",
       "      <td>-0.028095</td>\n",
       "      <td>-0.028470</td>\n",
       "      <td>-0.028421</td>\n",
       "      <td>2.417879</td>\n",
       "      <td>0.008347</td>\n",
       "      <td>0.000496</td>\n",
       "      <td>0.000193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10.627884</td>\n",
       "      <td>0.010901</td>\n",
       "      <td>-0.028504</td>\n",
       "      <td>-0.028434</td>\n",
       "      <td>2.5</td>\n",
       "      <td>None</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'class_weight': None, 'penalty': 'l1', 'C': 2.5}</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.028041</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028106</td>\n",
       "      <td>-0.028550</td>\n",
       "      <td>-0.029444</td>\n",
       "      <td>-0.028190</td>\n",
       "      <td>-0.028426</td>\n",
       "      <td>-0.028379</td>\n",
       "      <td>2.940321</td>\n",
       "      <td>0.005246</td>\n",
       "      <td>0.000562</td>\n",
       "      <td>0.000166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>8.484571</td>\n",
       "      <td>0.015911</td>\n",
       "      <td>-0.028575</td>\n",
       "      <td>-0.028502</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'class_weight': None, 'penalty': 'l1', 'C': 4.0}</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.028008</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028089</td>\n",
       "      <td>-0.028492</td>\n",
       "      <td>-0.029380</td>\n",
       "      <td>-0.028151</td>\n",
       "      <td>-0.028825</td>\n",
       "      <td>-0.028774</td>\n",
       "      <td>1.838608</td>\n",
       "      <td>0.008096</td>\n",
       "      <td>0.000563</td>\n",
       "      <td>0.000226</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  mean_score_time  mean_test_score  mean_train_score param_C  \\\n",
       "26      11.361621         0.016202        -0.028467         -0.028407     3.5   \n",
       "18      10.627884         0.010901        -0.028504         -0.028434     2.5   \n",
       "30       8.484571         0.015911        -0.028575         -0.028502       4   \n",
       "\n",
       "   param_class_weight param_penalty  \\\n",
       "26               None            l1   \n",
       "18               None            l1   \n",
       "30               None            l1   \n",
       "\n",
       "                                               params  rank_test_score  \\\n",
       "26  {'class_weight': None, 'penalty': 'l1', 'C': 3.5}                1   \n",
       "18  {'class_weight': None, 'penalty': 'l1', 'C': 2.5}                2   \n",
       "30  {'class_weight': None, 'penalty': 'l1', 'C': 4.0}                3   \n",
       "\n",
       "    split0_test_score       ...         split1_test_score  split1_train_score  \\\n",
       "26          -0.028033       ...                 -0.028089           -0.028499   \n",
       "18          -0.028041       ...                 -0.028106           -0.028550   \n",
       "30          -0.028008       ...                 -0.028089           -0.028492   \n",
       "\n",
       "    split2_test_score  split2_train_score  split3_test_score  \\\n",
       "26          -0.029276           -0.028095          -0.028470   \n",
       "18          -0.029444           -0.028190          -0.028426   \n",
       "30          -0.029380           -0.028151          -0.028825   \n",
       "\n",
       "    split3_train_score  std_fit_time  std_score_time  std_test_score  \\\n",
       "26           -0.028421      2.417879        0.008347        0.000496   \n",
       "18           -0.028379      2.940321        0.005246        0.000562   \n",
       "30           -0.028774      1.838608        0.008096        0.000563   \n",
       "\n",
       "    std_train_score  \n",
       "26         0.000193  \n",
       "18         0.000166  \n",
       "30         0.000226  \n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid.cv_results_).sort_values('rank_test_score')[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.52111135,  2.48564648, 89.76939399,  1.3127938 ]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=3.5, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_.fit(X_train_stack, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.41159104,   2.35318936, 103.72825921,   0.83373491]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted = grid.best_estimator_.predict(X_test_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94104\n",
      "868\n",
      "178\n",
      "337\n"
     ]
    }
   ],
   "source": [
    "test_session_id = test['session_id']\n",
    "test_real_typ = test['typ_count']\n",
    "\n",
    "count_false_false = 0\n",
    "count_false_true = 0\n",
    "count_true_false = 0\n",
    "count_true_true = 0\n",
    "\n",
    "with open('submission.csv', 'w') as out:\n",
    "    out.write('Session_id,Typ,RealTyp\\n')\n",
    "    for session, y, z in zip(test_session_id, predicted, test_real_typ):\n",
    "        if (y == 0 and z == 0):\n",
    "            count_false_false += 1\n",
    "        if (y == 0 and z >= 1):\n",
    "            count_false_true += 1\n",
    "        if (y == 1 and z == 0):\n",
    "            count_true_false += 1\n",
    "        if (y == 1 and z >= 1):\n",
    "            count_true_true += 1\n",
    "        out.write('%s,%s,%s\\n' % (session, y, z))\n",
    "        \n",
    "        \n",
    "print(count_false_false)#94104\n",
    "print(count_false_true)#868\n",
    "print(count_true_false)#178\n",
    "print(count_true_true)#337\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
